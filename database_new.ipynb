{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nrefseq - ncbi-ftp/gene/DATA/gene2refseq.gz\\npubmed - ncbi-ftp/gene/DATA/gene2pubmed.gz\\nensembl - ncbi-ftp/gene/DATA/gene2ensembl.gz\\nhuman - ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz\\nmart - useast.ensembl.org/index.html\\nneighbors - ncbi-ftp/gene/DATA/gene_neighbors.gz\\northologs - ncbi-ftp/gene/DATA/gene_orthologs.gz\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "refseq - ncbi-ftp/gene/DATA/gene2refseq.gz\n",
    "pubmed - ncbi-ftp/gene/DATA/gene2pubmed.gz\n",
    "ensembl - ncbi-ftp/gene/DATA/gene2ensembl.gz\n",
    "human - ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz\n",
    "mart - useast.ensembl.org/index.html\n",
    "neighbors - ncbi-ftp/gene/DATA/gene_neighbors.gz\n",
    "orthologs - ncbi-ftp/gene/DATA/gene_orthologs.gz\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# refseq = pd.read_table('gene2refseq')\n",
    "# pubmed = pd.read_table('gene2pubmed')\n",
    "# ensembl = pd.read_table('gene2ensembl')\n",
    "# mart = pd.read_csv('mart_export.txt',delimiter = ',')\n",
    "# neighbors = pd.read_table('gene_neighbors')\n",
    "# orthologs = pd.read_table('gene_orthologs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_table('Homo_sapiens.gene_info')\n",
    "aliases = human['Synonyms'].tolist()\n",
    "aliases_sep = []\n",
    "for i in range(len(aliases)):\n",
    "    my_list = aliases[i].split(\"|\")\n",
    "    my_list.append(human['Symbol'].iloc[i])\n",
    "    aliases_sep.append(my_list)\n",
    "human['Aliases'] = aliases_sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'refseq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-043b6d0ce27e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mcol_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mele\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefseq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpubmed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mensembl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhuman\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morthologs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# compare_sets(data_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'refseq' is not defined"
     ]
    }
   ],
   "source": [
    "def compare_sets(list_data):\n",
    "    for ele in list_data:\n",
    "        col_names = ele.columns\n",
    "        print(col_names)\n",
    "data_list = refseq,pubmed,ensembl,human,mart,neighbors,orthologs\n",
    "# compare_sets(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_translate(input_file, file_type, trans_list):\n",
    "    if (file_type == 'csv'):\n",
    "        df = pd.read_csv(input_file)\n",
    "    if (file_type == 'excel'):\n",
    "        df = pd.read_excel(input_file)\n",
    "    if (file_type == 'other'):\n",
    "        df = pd.read_table(input_file)\n",
    "    \n",
    "    for item in trans_list:\n",
    "        test_col = item[0]\n",
    "        reference_df = item[1]\n",
    "        reference_col = item[2]\n",
    "        output_col = item[3]\n",
    "        \n",
    "        \n",
    "        start_param = df[test_col].tolist()\n",
    "        in_list = reference_df[reference_col].tolist()\n",
    "        out_listoflist = []\n",
    "\n",
    "        for i in range(len(start_param)):\n",
    "            param = start_param[i]\n",
    "\n",
    "            match_list=[]\n",
    "            for j in range(len(in_list)):\n",
    "                if str(param) in str(in_list[j]):\n",
    "                    index_match = reference_df.iloc[j]\n",
    "                    match_list.append(index_match)\n",
    "\n",
    "            out_list = []\n",
    "            for k in range(len(match_list)):\n",
    "                if (output_col == 'MATCH'):\n",
    "                    out_list.append(match_list[k][reference_col])\n",
    "                else: \n",
    "                    out_list.append(match_list[k][output_col])\n",
    "\n",
    "            out_listoflist.append(out_list)\n",
    "        out_colname = 'output ' + reference_col\n",
    "        df[out_colname] = out_listoflist\n",
    "\n",
    "    \n",
    "        nonmatches_ind = [ind for ind, x in enumerate(df[out_colname]) if len(x)==0 or x != x or x=='-']\n",
    "        matches_ind = [ind for ind, x in enumerate(df[out_colname]) if len(x)!=0 or x == x or x!='-']\n",
    "        nonmatches = df.iloc[nonmatches_ind]\n",
    "        matches = df.iloc[matches_ind]\n",
    "        \n",
    "        return str(round(100*len(nonmatches)/len(df),4))+' % mismatch '\n",
    "#         print(round(100*len(nonmatches)/len(df),4),\" percent mismatch, \",input_file, 'to')\n",
    "    \n",
    "#     print(df)\n",
    "    \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Name of input data file\n",
    "input_file = 'md_2018_05_18_zhu_md-d-17-05991_sdc1.xlsx'\n",
    "\n",
    "### Type of file (excel, csv, or other)\n",
    "file_type = 'excel'\n",
    "\n",
    "### translation 1 test col name\n",
    "test_col1 = 'Gene Symbol'\n",
    "\n",
    "### translation 1 reference dataset (human,gene,mart)\n",
    "ref_df1 = human\n",
    "\n",
    "### translation 1 reference col name\n",
    "ref_col1 = 'Aliases'\n",
    "    \n",
    "### translation 1 output col name\n",
    "out_col1 = 'MATCH'\n",
    "\n",
    "### translation 1 use only if one translation, otherwise delete\n",
    "trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "print(combined_translate(input_file,file_type,trans_list))\n",
    "\n",
    "\n",
    "\n",
    "input_file = 'md_2018_05_18_zhu_md-d-17-05991_sdc1.xlsx'\n",
    "file_type = 'excel'\n",
    "test_col1 = 'Entrez Gene'\n",
    "ref_df1 = human\n",
    "ref_col1 = 'GeneID'\n",
    "out_col1 = 'MATCH'\n",
    "trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "print(combined_translate(input_file,file_type,trans_list))\n",
    "\n",
    "\n",
    "\n",
    "input_file = 'RA_loci.txt'\n",
    "file_type = 'csv'\n",
    "test_col1 = 'Gene'\n",
    "ref_df1 = human\n",
    "ref_col1 = 'Aliases'\n",
    "out_col1 = 'MATCH'\n",
    "trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "print(combined_translate(input_file,file_type,trans_list))\n",
    "\n",
    "\n",
    "\n",
    "input_file = 'Yamamoto.txt'\n",
    "file_type = 'other'\n",
    "test_col1 = 'Gene'\n",
    "ref_df1 = human\n",
    "ref_col1 = 'Aliases'\n",
    "out_col1 = 'MATCH'\n",
    "trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "print(combined_translate(input_file,file_type,trans_list))\n",
    "\n",
    "\n",
    "\n",
    "input_file = 'RADB.txt'\n",
    "file_type = 'other'\n",
    "test_col1 = 'Gene'\n",
    "ref_df1 = human\n",
    "ref_col1 = 'Aliases'\n",
    "out_col1 = 'MATCH'\n",
    "trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "print(combined_translate(input_file,file_type,trans_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lists(data_list):\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(len(data_list)):\n",
    "            if (i != j):\n",
    "                ### translation 1 test col name\n",
    "                test_col1 = data_list[i][1]\n",
    "\n",
    "                ### translation 1 reference dataset (human,gene,mart)\n",
    "                if (data_list[j][2] == 'csv'):\n",
    "                    ref_df1 = pd.read_csv(data_list[j][0])\n",
    "                if (data_list[j][2] == 'excel'):\n",
    "                    ref_df1 = pd.read_excel(data_list[j][0])\n",
    "                if (data_list[j][2] == 'other'):\n",
    "                    ref_df1 = pd.read_table(data_list[j][0])\n",
    "\n",
    "                ### translation 1 reference col name\n",
    "                ref_col1 = data_list[j][1]\n",
    "\n",
    "                ### translation 1 output col name\n",
    "                out_col1 = 'MATCH'\n",
    "                \n",
    "                trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "                match_percent = combined_translate(data_list[i][0], data_list[i][2], trans_list)\n",
    "                print(match_percent, data_list[i][0], 'to', data_list[j][0])\n",
    "#                 print(match_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rheumetoid Arthritis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'match_lists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f7cddf6db2de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0ml5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'okada.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Gene'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'other'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmatch_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'match_lists' is not defined"
     ]
    }
   ],
   "source": [
    "md_2018 = pd.read_excel('md_2018.xlsx')\n",
    "# https://journals.lww.com/md-journal/Fulltext/2018/06010/Identification_of_key_genes_in_rheumatoid.86.aspx\n",
    "# A total of 313 genes (DEGs) were identified to be differentially expressed between RA and NC samples\n",
    "\n",
    "ra_loci = pd.read_csv('RA_loci.txt')\n",
    "# https://academic.oup.com/view-large/27924154\n",
    "# Genetic loci associated with susceptibility to RA\n",
    "\n",
    "yamamoto = pd.read_table('Yamamoto.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4729856/\n",
    "# RA susceptible genes\n",
    "\n",
    "radb = pd.read_table('RADB.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4164886/\n",
    "# Genes and genetic regions that have the strongest association with RA susceptibility. \n",
    "\n",
    "okada = pd.read_table('okada.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3944098/#SD2\n",
    "# Novel rheumatoid arthritis risk loci identified by trans-ethnic GWAS meta-analysis in >100,000 subjects.\n",
    "\n",
    "\n",
    "l1 = ['md_2018.xlsx', 'Gene Symbol','excel']\n",
    "l2 = ['ra_loci.txt','Gene','csv']\n",
    "l3 = ['Yamamoto.txt','Gene','other']\n",
    "l4 = ['RADB.txt','Gene','other']\n",
    "l5 = ['okada.txt','Gene','other']\n",
    "\n",
    "match_lists([l1,l2,l3,l4,l5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t2 diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_supp = pd.read_excel('NIHMS795012-supplement-supp_table20.xlsx', header=2)\n",
    "dia_supp\n",
    "\n",
    "\n",
    "#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570412/\n",
    "#SNP coverage and T2D association for 222 candidate gene regions (-10 kb/+5 kb)\n",
    "gaulton_candidates = pd.read_excel('db_gaulton_candidates.xlsx')\n",
    "\n",
    "#Stage 1 T2D SNP association for 3,531 genotyped SNPs, sorted by pSNP\n",
    "gaulton = pd.read_excel('db_gaulton.xlsx')\n",
    "gaulton\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4377835/\n",
    "# Genetic loci associated with risk of T2D.\n",
    "prasad = pd.read_table('prasad_t2d.txt')\n",
    "\n",
    "# Genetic loci associated with glycemic traits.\n",
    "prasad_gly = pd.read_table('prasad_glycemic.txt')\n",
    "prasad_gly\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5537262/\n",
    "t2diacod = pd.read_table('t2diacod.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3319439/\n",
    "# Genes of interest within or near associated interval (genetic loci mapped by GWAS for myocardial \n",
    "# infarction or coronary artery disease)\n",
    "kathiresan = pd.read_table('kathiresan.txt')\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5266753/\n",
    "# 29 GWAS studies are included that identified more than 150 genomic loci associated with CAD and AMI \n",
    "barth = pd.read_excel('NIHMS764306-supplement-2.xlsx')\n",
    "barth\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3684247/\n",
    "joehanes = pd.read_table('Joehanes.txt')\n",
    "joehanes\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30586722/\n",
    "aragam = pd.read_table('Aragam.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "106\n",
      "105\n",
      "21\n",
      "100\n",
      "635\n",
      "216\n",
      "3531\n",
      "153\n",
      "24\n",
      "140\n",
      "49\n",
      "214\n",
      "35\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "def combine_datasets(listoflist):\n",
    "    \n",
    "    combined_data=[]\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(len(listoflist)):\n",
    "        list1 = listoflist[i]\n",
    "        combined_disease=[]\n",
    "        colnames = []\n",
    "        for j in range(len(list1)):\n",
    "            dataset = list1[j][0]\n",
    "            col_name = list1[j][1]\n",
    "            gene_list = dataset[col_name].tolist()\n",
    "            print(len(gene_list))\n",
    "        \n",
    "            combined_disease.append([gene_list])\n",
    "            colnames.append(col_name)\n",
    "        combined_data.append(combined_disease)\n",
    "    \n",
    "        label = [i] * len(list1)\n",
    "        label_list.append(label)\n",
    "    flat_list = [item for sublist in combined_data for item in sublist]\n",
    "    flat_labels = [item for sublist in label_list for item in sublist]\n",
    "    \n",
    "    df = pd.DataFrame(flat_list)\n",
    "    df['disease_type'] = flat_labels\n",
    "#     df.columns = colnames\n",
    "        \n",
    "    return df\n",
    "\n",
    "ra_list = [[md_2018, 'Gene Symbol'],\n",
    "[ra_loci, 'Gene'],\n",
    "[yamamoto, 'Gene'],\n",
    "[radb, 'Gene'],\n",
    "[okada, 'Gene']]\n",
    "\n",
    "\n",
    "\n",
    "t2d_list = [[dia_supp, 'Gene name'],\n",
    "[gaulton_candidates, 'Gene symbol(s)'],\n",
    "[gaulton, 'Gene symbol'],\n",
    "[prasad, 'Gene/Nearest Gene'],\n",
    "[prasad_gly, 'Gene/Nearest Gene'],\n",
    "[t2diacod, 'Gene']]\n",
    "\n",
    "heart_list = [[kathiresan, 'Gene'],\n",
    "[barth, 'Reported Gene(s)'],\n",
    "[joehanes, 'Gene Symbol'],\n",
    "[aragam, 'Gene']]\n",
    "\n",
    "gene_df = combine_datasets([ra_list,t2d_list,heart_list])\n",
    "# t2d_df = combine_datasets(t2d_list)\n",
    "# heart_df = combine_datasets(heart_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 1 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 1 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 1 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 1 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 2 2 2]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "x = gene_df.iloc[:,0].values.transpose()\n",
    "y = gene_df.iloc[:,1].values.transpose()\n",
    "# y = np.array([y])\n",
    "\n",
    "for i in range(gene_df.shape[0]):\n",
    "    x_train = np.delete(x, i)\n",
    "    y_train = np.delete(y, i)\n",
    "    print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,5,6])\n",
    "np.delete(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
