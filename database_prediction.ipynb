{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nrefseq - ncbi-ftp/gene/DATA/gene2refseq.gz\\npubmed - ncbi-ftp/gene/DATA/gene2pubmed.gz\\nensembl - ncbi-ftp/gene/DATA/gene2ensembl.gz\\nhuman - ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz\\nmart - useast.ensembl.org/index.html\\nneighbors - ncbi-ftp/gene/DATA/gene_neighbors.gz\\northologs - ncbi-ftp/gene/DATA/gene_orthologs.gz\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "refseq - ncbi-ftp/gene/DATA/gene2refseq.gz\n",
    "pubmed - ncbi-ftp/gene/DATA/gene2pubmed.gz\n",
    "ensembl - ncbi-ftp/gene/DATA/gene2ensembl.gz\n",
    "human - ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz\n",
    "mart - useast.ensembl.org/index.html\n",
    "neighbors - ncbi-ftp/gene/DATA/gene_neighbors.gz\n",
    "orthologs - ncbi-ftp/gene/DATA/gene_orthologs.gz\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# refseq = pd.read_table('gene2refseq')\n",
    "# pubmed = pd.read_table('gene2pubmed')\n",
    "# ensembl = pd.read_table('gene2ensembl')\n",
    "# mart = pd.read_csv('mart_export.txt',delimiter = ',')\n",
    "# neighbors = pd.read_table('gene_neighbors')\n",
    "# orthologs = pd.read_table('gene_orthologs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_table('Homo_sapiens.gene_info')\n",
    "aliases = human['Synonyms'].tolist()\n",
    "aliases_sep = []\n",
    "for i in range(len(aliases)):\n",
    "    my_list = aliases[i].split(\"|\")\n",
    "    my_list.append(human['Symbol'].iloc[i])\n",
    "    aliases_sep.append(my_list)\n",
    "human['Aliases'] = aliases_sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sets(list_data):\n",
    "    for ele in list_data:\n",
    "        col_names = ele.columns\n",
    "        print(col_names)\n",
    "# data_list = refseq,pubmed,ensembl,human,mart,neighbors,orthologs\n",
    "# compare_sets(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_translate(input_file, file_type, trans_list):\n",
    "    if (file_type == 'csv'):\n",
    "        df = pd.read_csv(input_file)\n",
    "    if (file_type == 'excel'):\n",
    "        df = pd.read_excel(input_file)\n",
    "    if (file_type == 'other'):\n",
    "        df = pd.read_table(input_file)\n",
    "    \n",
    "    for item in trans_list:\n",
    "        test_col = item[0]\n",
    "        reference_df = item[1]\n",
    "        reference_col = item[2]\n",
    "        output_col = item[3]\n",
    "        \n",
    "        \n",
    "        start_param = df[test_col].tolist()\n",
    "        in_list = reference_df[reference_col].tolist()\n",
    "        out_listoflist = []\n",
    "\n",
    "        for i in range(len(start_param)):\n",
    "            param = start_param[i]\n",
    "\n",
    "            match_list=[]\n",
    "            for j in range(len(in_list)):\n",
    "                if str(param) in str(in_list[j]):\n",
    "                    index_match = reference_df.iloc[j]\n",
    "                    match_list.append(index_match)\n",
    "\n",
    "            out_list = []\n",
    "            for k in range(len(match_list)):\n",
    "                if (output_col == 'MATCH'):\n",
    "                    out_list.append(match_list[k][reference_col])\n",
    "                else: \n",
    "                    out_list.append(match_list[k][output_col])\n",
    "\n",
    "            out_listoflist.append(out_list)\n",
    "        out_colname = 'output ' + reference_col\n",
    "        df[out_colname] = out_listoflist\n",
    "\n",
    "    \n",
    "        nonmatches_ind = [ind for ind, x in enumerate(df[out_colname]) if len(x)==0 or x != x or x=='-']\n",
    "        matches_ind = [ind for ind, x in enumerate(df[out_colname]) if len(x)!=0 or x == x or x!='-']\n",
    "        nonmatches = df.iloc[nonmatches_ind]\n",
    "        matches = df.iloc[matches_ind]\n",
    "        \n",
    "#         return str(round(100*len(nonmatches)/len(df),4))+' % mismatch '\n",
    "        return round(100*len(nonmatches)/len(df),4)\n",
    "#         print(round(100*len(nonmatches)/len(df),4),\" percent mismatch, \",input_file, 'to')\n",
    "    \n",
    "#     print(df)\n",
    "    \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lists(data_list):\n",
    "    \n",
    "    mismatch_list = []\n",
    "    class_ids = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(len(data_list)):\n",
    "#             if (i != j):\n",
    "            ### translation 1 test col name\n",
    "            test_col1 = data_list[i][1]\n",
    "\n",
    "            ### translation 1 reference dataset (human,gene,mart)\n",
    "            if (data_list[j][2] == 'csv'):\n",
    "                ref_df1 = pd.read_csv(data_list[j][0])\n",
    "            if (data_list[j][2] == 'excel'):\n",
    "                ref_df1 = pd.read_excel(data_list[j][0])\n",
    "            if (data_list[j][2] == 'other'):\n",
    "                ref_df1 = pd.read_table(data_list[j][0])\n",
    "\n",
    "            ### translation 1 reference col name\n",
    "            ref_col1 = data_list[j][1]\n",
    "\n",
    "            ### translation 1 output col name\n",
    "            out_col1 = 'MATCH'\n",
    "\n",
    "            trans_list = [[test_col1,ref_df1,ref_col1,out_col1]]\n",
    "            match_percent = combined_translate(data_list[i][0], data_list[i][2], trans_list)\n",
    "            mismatch_list.append(match_percent)\n",
    "            class_ids.append(data_list[j][3])\n",
    "#                 print(match_percent, data_list[i][0], 'to', data_list[j][0])\n",
    "\n",
    "        labels.append(data_list[i][3])\n",
    "    \n",
    "    match_list = []\n",
    "    for ele in mismatch_list:\n",
    "        match_list.append(100-ele)\n",
    "    match_array = np.array(match_list).reshape(15, 15)\n",
    "    \n",
    "    id_list = []\n",
    "    for ele in class_ids:\n",
    "        id_list.append(ele)\n",
    "    \n",
    "    return match_array,id_list,labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rheumetoid Arthritis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_2018 = pd.read_excel('md_2018.xlsx')\n",
    "# https://journals.lww.com/md-journal/Fulltext/2018/06010/Identification_of_key_genes_in_rheumatoid.86.aspx\n",
    "# A total of 313 genes (DEGs) were identified to be differentially expressed between RA and NC samples\n",
    "\n",
    "ra_loci = pd.read_csv('RA_loci.txt')\n",
    "# https://academic.oup.com/view-large/27924154\n",
    "# Genetic loci associated with susceptibility to RA\n",
    "\n",
    "yamamoto = pd.read_table('Yamamoto.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4729856/\n",
    "# RA susceptible genes\n",
    "\n",
    "radb = pd.read_table('RADB.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4164886/\n",
    "# Genes and genetic regions that have the strongest association with RA susceptibility. \n",
    "\n",
    "okada = pd.read_table('okada.txt')\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3944098/#SD2\n",
    "# Novel rheumatoid arthritis risk loci identified by trans-ethnic GWAS meta-analysis in >100,000 subjects.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t2 diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_supp = pd.read_excel('NIHMS795012-supplement-supp_table20.xlsx', header=2)\n",
    "dia_supp\n",
    "\n",
    "\n",
    "#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570412/\n",
    "#SNP coverage and T2D association for 222 candidate gene regions (-10 kb/+5 kb)\n",
    "gaulton_candidates = pd.read_excel('db_gaulton_candidates.xlsx')\n",
    "\n",
    "#Stage 1 T2D SNP association for 3,531 genotyped SNPs, sorted by pSNP\n",
    "gaulton = pd.read_excel('db_gaulton.xlsx')\n",
    "gaulton\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4377835/\n",
    "# Genetic loci associated with risk of T2D.\n",
    "prasad = pd.read_table('prasad_t2d.txt')\n",
    "\n",
    "# Genetic loci associated with glycemic traits.\n",
    "prasad_gly = pd.read_table('prasad_glycemic.txt')\n",
    "prasad_gly\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5537262/\n",
    "t2diacod = pd.read_table('t2diacod.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3319439/\n",
    "# Genes of interest within or near associated interval (genetic loci mapped by GWAS for myocardial \n",
    "# infarction or coronary artery disease)\n",
    "kathiresan = pd.read_table('kathiresan.txt')\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5266753/\n",
    "# 29 GWAS studies are included that identified more than 150 genomic loci associated with CAD and AMI \n",
    "barth = pd.read_excel('NIHMS764306-supplement-2.xlsx')\n",
    "barth\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3684247/\n",
    "joehanes = pd.read_table('Joehanes.txt')\n",
    "joehanes\n",
    "\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30586722/\n",
    "aragam = pd.read_table('Aragam.txt')\n",
    "\n",
    "l1 = ['md_2018.xlsx', 'Gene Symbol','excel','ra']\n",
    "l2 = ['ra_loci.txt','Gene','csv','ra']\n",
    "l3 = ['Yamamoto.txt','Gene','other','ra']\n",
    "l4 = ['RADB.txt','Gene','other','ra']\n",
    "l5 = ['okada.txt','Gene','other','ra']\n",
    "l6 = ['dia_supp.xlsx','Gene name', 'excel','dia']\n",
    "l7 = ['db_gaulton_candidates.xlsx', 'Gene symbol(s)', 'excel','dia']\n",
    "l8 = ['db_gaulton.xlsx', 'Gene symbol', 'excel','dia']\n",
    "l9 = ['prasad_t2d.txt', 'Gene/Nearest Gene', 'other','dia']\n",
    "l10 = ['prasad_glycemic.txt', 'Gene/Nearest Gene', 'other','dia']\n",
    "l11 = ['t2diacod.txt', 'Gene', 'other','dia']\n",
    "l12 = ['kathiresan.txt', 'Gene', 'other','hd']\n",
    "l13 = ['NIHMS764306-supplement-2.xlsx', 'Reported Gene(s)', 'excel','hd']\n",
    "l14 = ['Joehanes.txt', 'Gene Symbol', 'other','hd']\n",
    "l15 = ['Aragam.txt', 'Gene', 'other','hd']\n",
    "\n",
    "combined_datasets = [l1,l2,l3,l4,l5,l6,l7,l8,l9,l10,l11,l12,l13,l14,l15]\n",
    "\n",
    "matchArray,idList,labelList = match_lists(combined_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from itertools import islice \n",
    "\n",
    "\n",
    "def avg_classifiers(match_array, id_list,num_classifiers):\n",
    "    \n",
    "    count_dups = [sum(1 for _ in group) for _, group in groupby(id_list)]\n",
    "    \n",
    "    avg_listoflist = []\n",
    "    for i in range(match_array.shape[0]):\n",
    "#         for j in range(match_array.shape[1]):\n",
    "#             print(id_list[j+i*match_array.shape[1]])\n",
    "#             print(match_array[i,j])\n",
    "#         print(match_array[i])\n",
    "        sub_list = []\n",
    "        for k in range(num_classifiers):\n",
    "            \n",
    "            sub_list.append(count_dups[k+i*num_classifiers])\n",
    "\n",
    "            slice_input = iter(match_array[i]) \n",
    "        slice_output = [list(islice(slice_input, elem)) for elem in sub_list] \n",
    "        \n",
    "        avg_output = []\n",
    "        for item in slice_output:\n",
    "            avg_output.append(sum(item)/len(item))\n",
    "        avg_listoflist.append(avg_output)\n",
    "    return np.array(avg_listoflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.1949</td>\n",
       "      <td>3.1949</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>3.1949</td>\n",
       "      <td>3.5144</td>\n",
       "      <td>1.5974</td>\n",
       "      <td>1.5974</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0703</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.4340</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>84.9057</td>\n",
       "      <td>23.5849</td>\n",
       "      <td>85.8491</td>\n",
       "      <td>5.6604</td>\n",
       "      <td>5.6604</td>\n",
       "      <td>5.6604</td>\n",
       "      <td>3.7736</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6190</td>\n",
       "      <td>80.9524</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>19.0476</td>\n",
       "      <td>90.4762</td>\n",
       "      <td>5.7143</td>\n",
       "      <td>6.6667</td>\n",
       "      <td>6.6667</td>\n",
       "      <td>3.8095</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7619</td>\n",
       "      <td>80.9524</td>\n",
       "      <td>85.7143</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>85.7143</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.7619</td>\n",
       "      <td>4.7619</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0000</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.7323</td>\n",
       "      <td>1.1024</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>1.8898</td>\n",
       "      <td>1.8898</td>\n",
       "      <td>14.8031</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>2.5197</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.4724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.7778</td>\n",
       "      <td>4.1667</td>\n",
       "      <td>4.6296</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>4.6296</td>\n",
       "      <td>7.4074</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>96.7593</td>\n",
       "      <td>4.1667</td>\n",
       "      <td>1.8519</td>\n",
       "      <td>6.9444</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>1.8519</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.7862</td>\n",
       "      <td>4.4747</td>\n",
       "      <td>5.0694</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>5.0694</td>\n",
       "      <td>8.6095</td>\n",
       "      <td>99.9717</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.2569</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>5.6924</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>1.8408</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.6144</td>\n",
       "      <td>5.2288</td>\n",
       "      <td>5.2288</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.5752</td>\n",
       "      <td>71.2418</td>\n",
       "      <td>10.4575</td>\n",
       "      <td>10.4575</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>1.9608</td>\n",
       "      <td>4.5752</td>\n",
       "      <td>0.6536</td>\n",
       "      <td>7.8431</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.6667</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.4286</td>\n",
       "      <td>3.5714</td>\n",
       "      <td>3.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.5714</td>\n",
       "      <td>5.7143</td>\n",
       "      <td>12.1429</td>\n",
       "      <td>12.1429</td>\n",
       "      <td>3.5714</td>\n",
       "      <td>1.4286</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.5714</td>\n",
       "      <td>7.1429</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0408</td>\n",
       "      <td>2.0408</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0408</td>\n",
       "      <td>12.2449</td>\n",
       "      <td>4.0816</td>\n",
       "      <td>4.0816</td>\n",
       "      <td>4.0816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1224</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>75.5102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.4019</td>\n",
       "      <td>1.8692</td>\n",
       "      <td>1.8692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.8692</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>20.5607</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.8571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   100.0000    3.1949    3.1949    0.9585    3.1949    3.5144    1.5974   \n",
       "1     9.4340  100.0000   84.9057   23.5849   85.8491    5.6604    5.6604   \n",
       "2     7.6190   80.9524  100.0000   19.0476   90.4762    5.7143    6.6667   \n",
       "3     4.7619   80.9524   85.7143  100.0000   85.7143    0.0000    4.7619   \n",
       "4     8.0000   77.0000   86.0000   20.0000  100.0000    6.0000    7.0000   \n",
       "5     1.7323    1.1024    0.9449    0.1575    0.7874  100.0000    1.8898   \n",
       "6     2.7778    4.1667    4.6296    0.9259    4.6296    7.4074  100.0000   \n",
       "7     4.7862    4.4747    5.0694    0.5947    5.0694    8.6095   99.9717   \n",
       "8     2.6144    5.2288    5.2288    0.0000    4.5752   71.2418   10.4575   \n",
       "9     0.0000    0.0000    0.0000    0.0000    0.0000   16.6667   12.5000   \n",
       "10   11.4286    3.5714    3.5714    0.0000    3.5714    5.7143   12.1429   \n",
       "11    0.0000    2.0408    2.0408    0.0000    2.0408   12.2449    4.0816   \n",
       "12    1.4019    1.8692    1.8692    0.0000    1.8692    4.2056    0.4673   \n",
       "13    0.0000    2.8571    0.0000    0.0000    0.0000    0.0000    0.0000   \n",
       "14    0.0000    0.0000    0.0000    0.0000    0.0000   10.0000    3.3333   \n",
       "\n",
       "           7         8         9        10        11        12        13  \\\n",
       "0     1.5974    0.6390    0.0000    6.0703    0.3195    0.6390    0.3195   \n",
       "1     5.6604    3.7736    0.0000    0.9434    0.0000    0.9434    0.0000   \n",
       "2     6.6667    3.8095    0.0000    0.9524    0.0000    0.9524    0.0000   \n",
       "3     4.7619    0.0000    0.0000    0.0000    0.0000    0.0000    0.0000   \n",
       "4     7.0000    4.0000    0.0000    1.0000    0.0000    1.0000    0.0000   \n",
       "5     1.8898   14.8031    0.7874    0.7874    0.9449    2.5197    0.3150   \n",
       "6    96.7593    4.1667    1.8519    6.9444    0.9259    1.8519    0.0000   \n",
       "7   100.0000    3.2569    0.7647    5.6924    0.7647    1.8408    0.0000   \n",
       "8    10.4575  100.0000    1.9608    4.5752    0.6536    7.8431    0.0000   \n",
       "9    12.5000   25.0000  100.0000    0.0000    0.0000    4.1667    0.0000   \n",
       "10   12.1429    3.5714    1.4286  100.0000    3.5714    7.1429    0.7143   \n",
       "11    4.0816    4.0816    0.0000    6.1224  100.0000   75.5102    0.0000   \n",
       "12    0.4673    0.9346    0.9346    4.2056   20.5607  100.0000    0.0000   \n",
       "13    0.0000    0.0000    0.0000    0.0000    0.0000    0.0000  100.0000   \n",
       "14    3.3333    0.0000    0.0000    3.3333    0.0000    0.0000    0.0000   \n",
       "\n",
       "          14  \n",
       "0     0.0000  \n",
       "1     0.0000  \n",
       "2     0.0000  \n",
       "3     0.0000  \n",
       "4     0.0000  \n",
       "5     0.4724  \n",
       "6     0.4630  \n",
       "7     0.6797  \n",
       "8     0.6536  \n",
       "9     0.0000  \n",
       "10    0.7143  \n",
       "11    2.0408  \n",
       "12    0.0000  \n",
       "13    0.0000  \n",
       "14  100.0000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matchArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DIA</th>\n",
       "      <th>HD</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.10864</td>\n",
       "      <td>2.236417</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.75474</td>\n",
       "      <td>3.616367</td>\n",
       "      <td>0.235850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.61904</td>\n",
       "      <td>3.968267</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.42858</td>\n",
       "      <td>1.587300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.20000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.94490</td>\n",
       "      <td>20.026250</td>\n",
       "      <td>1.063000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.42592</td>\n",
       "      <td>36.188283</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.99888</td>\n",
       "      <td>36.382533</td>\n",
       "      <td>0.821300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.52944</td>\n",
       "      <td>33.115467</td>\n",
       "      <td>2.287575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>27.777783</td>\n",
       "      <td>1.041675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.42856</td>\n",
       "      <td>22.500017</td>\n",
       "      <td>3.035725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.22448</td>\n",
       "      <td>5.102017</td>\n",
       "      <td>44.387750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.40190</td>\n",
       "      <td>1.869167</td>\n",
       "      <td>30.140175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.57142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.333317</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RA        DIA         HD  Classifier\n",
       "0   22.10864   2.236417   0.319500           0\n",
       "1   60.75474   3.616367   0.235850           0\n",
       "2   59.61904   3.968267   0.238100           0\n",
       "3   71.42858   1.587300   0.000000           0\n",
       "4   58.20000   4.166667   0.250000           0\n",
       "5    0.94490  20.026250   1.063000           1\n",
       "6    3.42592  36.188283   0.810200           1\n",
       "7    3.99888  36.382533   0.821300           1\n",
       "8    3.52944  33.115467   2.287575           1\n",
       "9    0.00000  27.777783   1.041675           1\n",
       "10   4.42856  22.500017   3.035725           1\n",
       "11   1.22448   5.102017  44.387750           2\n",
       "12   1.40190   1.869167  30.140175           2\n",
       "13   0.57142   0.000000  25.000000           2\n",
       "14   0.00000   3.333317  25.000000           2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = pd.DataFrame(matchArray)\n",
    "matches\n",
    "averages = avg_classifiers(matchArray,idList,3)\n",
    "col_names = ['RA','DIA','HD']\n",
    "averages_df = pd.DataFrame(averages,columns=col_names)\n",
    "\n",
    "averages_df['Classifier'] = labelList\n",
    "averages_df=averages_df.replace('ra',0)\n",
    "averages_df=averages_df.replace('dia',1)\n",
    "averages_df=averages_df.replace('hd',2)\n",
    "averages_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rheumetoid arthritis vs dia\n",
      "Testing number:  7\n",
      "Target =  1.0 dia\n",
      "Prediction:  [0.99984913] DIA\n",
      "sklearn logreg coefficients:  [[-0.2270313   0.26629625  0.02078453]] Intercept:  [0.0011844]\n",
      "sklearn final cost =  0.0025291476793626103\n",
      " \n",
      "dia vs heart disease\n",
      "Testing number:  8\n",
      "Target =  1.0 dia\n",
      "Prediction:  [0.00028125] DIA\n",
      "sklearn logreg coefficients:  [[-0.02655955 -0.26043793  0.23830804]] Intercept:  [-0.00286458]\n",
      "sklearn final cost =  1.0086434061053942\n",
      " \n",
      "rheumetoid vs heart disease\n",
      "Testing number:  10\n",
      "Target =  2.0 dia\n",
      "Prediction:  [0.99994254] HD\n",
      "sklearn logreg coefficients:  [[-0.21077687 -0.00901372  0.22687348]] Intercept:  [-0.001985]\n",
      "sklearn final cost =  -2.211760888168444\n"
     ]
    }
   ],
   "source": [
    "def cost_func(X, y, theta, fit_intercept = True):\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    z = np.dot(X, theta)\n",
    "    h = 1 / (1+np.exp(-z))\n",
    "    c = -(1/len(y)) * np.sum(y*np.log(h)+(1-y)*np.log(1-h))\n",
    "    return c\n",
    "\n",
    "def predict(x, theta):\n",
    "    \n",
    "    ## add intercept\n",
    "    intercept = np.ones((x.shape[0], 1))\n",
    "    x_wintercept = np.concatenate((intercept, x), axis=1)\n",
    "    \n",
    "    x_dotproduct = np.dot(x_wintercept, theta)\n",
    "    g_sigmoid = 1 / (1+np.exp(-x_dotproduct))\n",
    "    return g_sigmoid\n",
    "\n",
    "def log_reg(X, y, array_len, case_num):\n",
    "\n",
    "    rand_sample = random.randint(0,array_len-1)\n",
    "    testing_X = X[rand_sample:rand_sample+1,]\n",
    "    testing_y = y[rand_sample]\n",
    "    training_X = np.delete(X, rand_sample, axis=0)\n",
    "    training_y = np.delete(y, rand_sample)\n",
    "\n",
    "    lf = LogisticRegression(random_state = 0, solver='liblinear',multi_class = 'auto').fit(training_X, training_y)\n",
    "    theta = np.append(lf.intercept_,lf.coef_)\n",
    "    sklearn_cost = cost_func(training_X, training_y, theta)\n",
    "    prob1 = predict(testing_X, theta)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Predict which dataset prob1 belongs\n",
    "    if (case_num == 1):\n",
    "        print(\"rheumetoid arthritis vs dia\")\n",
    "        if (prob1 < 0.5):\n",
    "            dataset = col_names[0]\n",
    "        else: dataset = col_names[1]\n",
    "            \n",
    "        print(\"Testing number: \", rand_sample)\n",
    "        print(\"Target = \",testing_y, labelList[rand_sample])\n",
    "        print(\"Prediction: \", prob1, dataset)\n",
    "        \n",
    "    if (case_num == 2):\n",
    "        print(\"dia vs heart disease\")\n",
    "        if (prob1 < 0.5):\n",
    "            dataset = col_names[1]\n",
    "        else: dataset = col_names[2]\n",
    "        print(\"Testing number: \", rand_sample+5)\n",
    "        print(\"Target = \",testing_y, labelList[rand_sample+5])\n",
    "        print(\"Prediction: \", prob1, dataset)  \n",
    "        \n",
    "    if (case_num == 3):\n",
    "        print(\"rheumetoid vs heart disease\")\n",
    "        if (prob1 < 0.5):\n",
    "            dataset = col_names[0]\n",
    "        else: dataset = col_names[2]\n",
    "        if (rand_sample<5):\n",
    "            print(\"Testing number: \", rand_sample)\n",
    "            print(\"Target = \",testing_y, labelList[rand_sample])\n",
    "        else: \n",
    "            print(\"Testing number: \", rand_sample+5)\n",
    "            print(\"Target = \",testing_y, labelList[rand_sample+5])\n",
    "        print(\"Prediction: \", prob1, dataset)  \n",
    "        \n",
    "    print(\"sklearn logreg coefficients: \",lf.coef_, \"Intercept: \",lf.intercept_)\n",
    "    print(\"sklearn final cost = \",sklearn_cost)\n",
    "\n",
    "X1 = np.array(averages_df)[0:11,0:3]\n",
    "y1 = np.array(averages_df)[0:11,3]\n",
    "log_reg(X1, y1, 11, 1)\n",
    "print(\" \")\n",
    "X2 = np.array(averages_df)[5:15,0:3]\n",
    "y2 = np.array(averages_df)[5:15,3]\n",
    "log_reg(X2,y2,10, 2)\n",
    "print(\" \")\n",
    "# X3 = np.array(averages_df)[0:5, 11:14]\n",
    "X3 = np.concatenate((np.array(averages_df)[0:5,0:3],np.array(averages_df)[11:15,0:3]), axis=0)\n",
    "y3 = np.concatenate((np.array(averages_df)[0:5,3],np.array(averages_df)[11:15,3]), axis=0)\n",
    "log_reg(X3,y3,9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_datasets(listoflist):\n",
    "    \n",
    "    combined_data=[]\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(len(listoflist)):\n",
    "        list1 = listoflist[i]\n",
    "        combined_disease=[]\n",
    "        colnames = []\n",
    "        for j in range(len(list1)):\n",
    "            dataset = list1[j][0]\n",
    "            col_name = list1[j][1]\n",
    "            gene_list = dataset[col_name].tolist()\n",
    "#             print(len(gene_list))\n",
    "        \n",
    "            combined_disease.append([gene_list])\n",
    "            colnames.append(col_name)\n",
    "        combined_data.append(combined_disease)\n",
    "    \n",
    "        label = [i] * len(list1)\n",
    "        label_list.append(label)\n",
    "    flat_list = [item for sublist in combined_data for item in sublist]\n",
    "    flat_labels = [item for sublist in label_list for item in sublist]\n",
    "    \n",
    "    df = pd.DataFrame(flat_list)\n",
    "    df['disease_type'] = flat_labels\n",
    "#     df.columns = colnames\n",
    "        \n",
    "    return df\n",
    "\n",
    "ra_list = [[md_2018, 'Gene Symbol'],\n",
    "[ra_loci, 'Gene'],\n",
    "[yamamoto, 'Gene'],\n",
    "[radb, 'Gene'],\n",
    "[okada, 'Gene']]\n",
    "\n",
    "\n",
    "\n",
    "t2d_list = [[dia_supp, 'Gene name'],\n",
    "[gaulton_candidates, 'Gene symbol(s)'],\n",
    "[gaulton, 'Gene symbol'],\n",
    "[prasad, 'Gene/Nearest Gene'],\n",
    "[prasad_gly, 'Gene/Nearest Gene'],\n",
    "[t2diacod, 'Gene']]\n",
    "\n",
    "heart_list = [[kathiresan, 'Gene'],\n",
    "[barth, 'Reported Gene(s)'],\n",
    "[joehanes, 'Gene Symbol'],\n",
    "[aragam, 'Gene']]\n",
    "\n",
    "gene_df = combine_datasets([ra_list,t2d_list,heart_list])\n",
    "# t2d_df = combine_datasets(t2d_list)\n",
    "# heart_df = combine_datasets(heart_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gene_df.iloc[:,0].values.transpose()\n",
    "y = gene_df.iloc[:,1].values.transpose()\n",
    "# y = np.array([y])\n",
    "\n",
    "for i in range(gene_df.shape[0]):\n",
    "    x_train = np.delete(x, i)\n",
    "    y_train = np.delete(y, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
